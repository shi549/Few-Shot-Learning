{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Section 1: Introduction**\n\nThis notebook implements the Few Shot Learning Meta-Learning method described in https://openreview.net/forum?id=rJY0-Kcll. This section imports the required libraries, sets the computation device, and defines the hyperparameters. ","metadata":{}},{"cell_type":"code","source":"! pip install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport glob\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n# import torchvision.models as models\n\nfrom torch.optim import Adam\nfrom torch.utils import data\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchsummary import summary\nfrom PIL import Image\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# from collections import OrderedDict\n# from tensorboardX import SummaryWriter\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU is not available, using CPU instead\")\n\n# HYPERPARAMETERS\nNUM_EPOCH = 10\nNUM_SHOT = 5    # 5-shot\n# NUM_SHOT = 1    # 1-shot\nNUM_EVAL = 3*NUM_SHOT\nNUM_CLASS = 5\nBATCH_SIZE = NUM_CLASS*NUM_SHOT\nNUM_EPI_TRAIN = 12000  # reference repo: 50000\nNUM_EPI_TEST = 1000\nNUM_EPI_EVAL = 100\nMOMENTUM = 0.95\nEPS = 1e-03\nGRAD_CLIP = 0.25\nLR_DECAY = 0.0005\nLR_INIT = 0.001\nIMAGE_DIM = 64  # cifar-100, omniglot\n# IMAGE_DIM = 96 # miniImageNet\nINPUT_SIZE = 4\nHIDDEN_SIZE = 20\nVAL_FREQ = 100\n\n# PATHS\nOUTPUT_DIR = '/kaggle/working/'\n\n# # CIFAR-100\n# TRAIN_IMG_DIR = '/kaggle/input/cifar100-fs/cifar100/metatrain'\n# TEST_IMG_DIR = '/kaggle/input/cifar100-fs/cifar100/metatest'\n# VAL_IMG_DIR = '/kaggle/input/cifar100-fs/cifar100/metaval'\n\n# # MiniImageNet\n# TRAIN_IMG_DIR = '/kaggle/input/MiniImageNet/miniImagenet/train'\n# TEST_IMG_DIR = '/kaggle/input/MiniImageNet/miniImagenet/test'\n# VAL_IMG_DIR = '/kaggle/input/MiniImageNet/miniImagenet/val'\n\n# Omniglot\nBG_IMG_DIR = OUTPUT_DIR + 'bg_images'  # Background images\nos.makedirs(BG_IMG_DIR, exist_ok=True)\nEV_IMG_DIR = OUTPUT_DIR + 'ev_images'  # Evaluation images\nos.makedirs(EV_IMG_DIR, exist_ok=True)\n\ntorchvision.datasets.Omniglot(root=BG_IMG_DIR, background=True, transform=None, target_transform=None, download=True)\nBG_IMG_DIR = BG_IMG_DIR + '/omniglot-py/images_background'\ntorchvision.datasets.Omniglot(root=EV_IMG_DIR, background=False, transform=None, target_transform=None, download=True)\nEV_IMG_DIR = EV_IMG_DIR + '/omniglot-py/images_evaluation'\n# os.listdir(EV_IMG_DIR + '/omniglot-py/images_evaluation')\n\nTRAIN_IMG_DIR = OUTPUT_DIR + 'train'\nTEST_IMG_DIR = OUTPUT_DIR + 'test'\nVAL_IMG_DIR = OUTPUT_DIR + 'val'\n\nLOG_DIR = OUTPUT_DIR + 'tblogs'  # tensorboard logs\nCHECKPOINT_DIR = OUTPUT_DIR + 'models'  # model checkpoints=\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 2: Class definitions**\n\nThis section defines the classes used for the training routine. They are:\n\n* Learner: CNN4 architecture commonly used for Mini ImageNet\n\n* MetaLearner: Two-layer LSTM architecture to learn the optimal parameters for Learner. First layer is a normal LSTM cell, and second layer is a customized MetaLSTMCell\n\n* MetaLSTMCell: 2nd layer of LSTM meta-learner as proposed by the authors. The update equations for the parameters are:\n$$c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c_t}$$\n    * $c_t = \\theta_t$ are the Learner NN parameters at time $t$\n    * $\\tilde{c_t} = -\\nabla_{\\theta_{t-1}} \\mathcal{L}_t$ is the candidate cell state, also equal to the negative gradient of the loss at time $t$\n    * $i_t = \\alpha_t$ is the learning rate at time step $t$ and is given by the sigmoid function of:\n    $$i_t = \\sigma \\,(\\boldsymbol{W}_I \\cdot [\\nabla_{\\theta_{t-1}} \\mathcal{L}_t, \\mathcal{L}_t, c_{t-1}, i_{t-1}] + \\boldsymbol{b}_I)$$\n    * $f_t$ is the forget gate strength at time step $t$ and is given by the sigmoid function of:\n    $$f_t = \\sigma \\,(\\boldsymbol{W}_F \\cdot [\\nabla_{\\theta_{t-1}} \\mathcal{L}_t, \\mathcal{L}_t, c_{t-1}, f_{t-1}] + \\boldsymbol{b}_F)$$\n\n* CustomDataset: Dataset class that returns the image and its label as two tensors\n\n* EpisodeDataset: Dataset class for training and evaluating few-shot learning models by episodes. Each episode will contain num_class classes, with num_shot training images from each class, and num_eval query images from each of the num_class classes.\n\n* EpisodeSampler: Sampler class that generates episodes for few-shot learning.","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \"\"\"\n    A custom dataset class that returns the image and its label as two tensors.\n    \"\"\"\n    \n    def __init__(self, images, label, transform=None):\n        self.images = images\n        self.label = label\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        image = Image.open(self.images[idx]).convert('RGB')\n        if self.transform is not None:\n            image = self.transform(image)\n            \n        # Convert image and label to PyTorch tensors\n        image_ten = torch.Tensor(image)\n        label_ten = torch.tensor(self.label)\n\n        return image_ten, label_ten\n\n    def __len__(self):\n        return len(self.images)\n\nclass EpisodeDataset(Dataset):\n    \"\"\"\n    A custom dataset for training and evaluating few-shot learning models by episodes.\n    \"\"\"\n\n    def __init__(self, root, num_shot=5, num_eval=15, transform=None):\n#         root = os.path.join(root, phase)\n        self.labels = sorted(os.listdir(root))\n        \n        images = []\n        self.episode_loader = []\n        \n        for label in self.labels:\n            images.append(glob.glob(os.path.join(root, label, '*')))\n            \n        for idx, _ in enumerate(self.labels):\n            loader = DataLoader(CustomDataset(images=images[idx], label=idx, transform=transform),\n                                batch_size=num_shot + num_eval, shuffle=True, num_workers=0)\n            self.episode_loader.append(loader)\n\n    def __getitem__(self, idx):\n        return next(iter(self.episode_loader[idx]))\n\n    def __len__(self):\n        return len(self.labels)\n\nclass EpisodeSampler(Sampler):\n    \"\"\"\n    A sampler that generates episodes for few-shot learning.\n    \"\"\"\n\n    def __init__(self, total_classes, num_class, num_episode):\n        self.total_classes = total_classes\n        self.num_class = num_class\n        self.num_episode = num_episode\n\n    def __iter__(self):\n        for i in range(self.num_episode):\n            episode_classes = torch.randperm(self.total_classes)[:self.num_class]\n            yield episode_classes\n\n    def __len__(self):\n        return self.num_episode","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLASS DEFINITIONS\nclass Learner(nn.Module):\n    \"\"\"\n    Learner module uses a simple CNN containing 4 convolutional layers, each of which is a 3 × 3\n    convolution with 32 filters, followed by batch normalization, a ReLU non-linearity, and lastly a\n    2 × 2 max-pooling. The network then has a final linear layer followed by a softmax for the number\n    of classes being considered. The loss function L is the average negative log-probability assigned by\n    the learner to the correct class.\n    \"\"\"\n    \n    def __init__(self, num_class=NUM_CLASS, image_size=IMAGE_DIM, momentum=MOMENTUM, eps=EPS):\n        super(Learner, self).__init__()\n        self.image_size = image_size\n        \n        # Model: four conv layers and one linear layer\n        self.model = nn.ModuleDict({\n            'conv1': nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            'norm1': nn.BatchNorm2d(32, momentum=momentum, eps=eps),\n            'relu1': nn.ReLU(),\n            'pool1': nn.MaxPool2d(kernel_size=2),\n            \n            'conv2': nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            'norm2': nn.BatchNorm2d(32, momentum=momentum, eps=eps),\n            'relu2': nn.ReLU(),\n            'pool2': nn.MaxPool2d(kernel_size=2),\n            \n            'conv3': nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            'norm3': nn.BatchNorm2d(32, momentum=momentum, eps=eps),\n            'relu3': nn.ReLU(),\n            'pool3': nn.MaxPool2d(kernel_size=2),\n            \n            'conv4': nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            'norm4': nn.BatchNorm2d(32, momentum=momentum, eps=eps),\n            'relu4': nn.ReLU(),\n            'pool4': nn.MaxPool2d(kernel_size=2),\n            \n            'flatten': nn.Flatten(),\n            'linear': nn.Linear(32 * (image_size // 16) ** 2, num_class) # 'pool4' out-channels * (image_size // 16) ** 2\n        })\n        \n        # Softmax layer\n        self.softmax_layer = nn.Softmax(dim=1)\n        \n        # CEL as loss function\n        self.criterion = nn.CrossEntropyLoss()\n\n    # Forward propagation\n    def forward(self, x):\n        for layer in self.model.values():\n            x = layer(x)\n#             print(x.size())\n#         x = x.view(x.size(0), -1)\n        x = self.softmax_layer(x)\n        return x\n    \n    # Flatten parameters\n    def get_flat_params(self):\n        return torch.cat([p.view(-1) for p in self.model.parameters()], 0)\n        # Initialize empty list to store flattened parameters\n        flat_params = []\n        \n        # Iterate through each parameter in the model\n        for param in self.model.parameters():\n            flat_param = param.view(-1)\n            flat_params.append(flat_param)\n            \n        # Concatenate all the flat parameters into a single tensor\n        return torch.cat(flat_params, 0)\n        \n    # Copy flattened parameters of cI for transfer later\n    def copy_flat_params(self, cI):\n        idx = 0\n        \n        # Iterate over learnable parameters (model)\n        for param in self.model.parameters():\n            flattened_len = param.view(-1).size(0)\n            \n            # Copy the corresponding values from cI into the parameter tensor\n            param.data.copy_(cI[idx: idx+flattened_len].view_as(param))\n            idx += flattened_len\n        \n    # Replace weights and biases with cI values\n    def transfer_params(self, learner, cI):\n        \n        # Copy the running mean/variance of batch normalization layers from trained_net\n        self.load_state_dict(learner.state_dict())\n        \n        # Replace the weights and biases of each module with cI\n        index = 0\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d) or \\\n               isinstance(module, nn.BatchNorm2d) or \\\n               isinstance(module, nn.Linear):\n\n                # Replace the weights with cI\n                weight_len = module.weight.view(-1).size(0)\n                module._parameters['weight'] = cI[index:index+weight_len].view_as(module.weight).clone()\n                index += weight_len\n\n                # Replace the biases with cI\n                if module.bias is not None:\n                    bias_len = module.bias.view(-1).size(0)\n                    module._parameters['bias'] = cI[index:index+bias_len].view_as(module.bias).clone()\n                    index += bias_len        \n                    \n    # Erase running stats\n    def erase_batch_stats(self):       \n        for module in self.modules():\n            # Erase the running mean and variance of batch normalization layers\n            if isinstance(module, nn.BatchNorm2d): \n                module.reset_running_stats()\n#                 print('Erased running stats')\n                \nclass MetaLSTMCell(nn.Module):\n    \"\"\"\n    MetaLSTMCell Learner module that learns an update rule for training a neural network.\n    C_t = f_t * C_{t-1} - i_t * \\Delta_{\\theta_{t-1}} L_t\n    \"\"\"\n\n    def __init__(self, input_size, hidden_size, n_learner_params):\n        super(MetaLSTMCell, self).__init__()\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.n_learner_params = n_learner_params\n        self.cI = nn.Parameter(torch.Tensor(n_learner_params, 1))\n\n        # Weights and biases of forget gate\n        self.WF = nn.Parameter(torch.Tensor(input_size + 2, hidden_size))\n        self.bF = nn.Parameter(torch.Tensor(1, hidden_size))\n\n        # Weights and biases of input gate\n        self.WI = nn.Parameter(torch.Tensor(input_size + 2, hidden_size))\n        self.bI = nn.Parameter(torch.Tensor(1, hidden_size))\n\n        # Initialize weights and biases with random values\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        for weight in self.parameters():\n            nn.init.uniform_(weight, -0.01, 0.01)\n\n        # Initialize the forget bias to a high value and the input bias to a low value\n        # so that the model starts with gradient descent\n        nn.init.uniform_(self.bF, 4, 6)\n        nn.init.uniform_(self.bI, -6, -4)\n\n    def init_cI(self, flat_params):\n        self.cI.data.copy_(flat_params.unsqueeze(1))\n#         print('!',self.cI.shape,flat_params.shape)\n#         self.cI.copy_(flat_params.unsqueeze(1))\n\n    def forward(self, inputs, hx=None):\n        \n        lstm1_hidden_output, grad = inputs\n        batch, _ = lstm1_hidden_output.size()\n\n        # Initialize the previous state if not provided\n        if hx is None:\n            f_prev = torch.zeros((batch, self.hidden_size)).to(self.WF.device)\n            i_prev = torch.zeros((batch, self.hidden_size)).to(self.WI.device)\n            c_prev = self.cI\n            hx = [f_prev, i_prev, c_prev]\n        else:\n            f_prev, i_prev, c_prev = hx\n        \n#         print(f' meta lstm c_prev shape: {  c_prev.shape}')\n#         print(f' meta lstm f_prev shape: {  f_prev.shape}')\n#         print(f' meta lstm i_prev shape: {  i_prev.shape}')\n#         print(f' lstm1_hidden_output shape: {lstm1_hidden_output.shape}')\n        test = torch.cat((lstm1_hidden_output, c_prev, f_prev), 1)\n#         print(f'cat :{test.shape}')\n#         print(f'self.WF :{self.WF.shape}')\n        # Compute the forget gate using the previous forget gate, cell state, input and gradients\n        f_next = torch.mm(torch.cat((lstm1_hidden_output, c_prev, f_prev), 1), self.WF) + self.bF.expand_as(f_prev)\n        sig_f_next = torch.sigmoid(f_next)\n\n        # Compute the input gate using the previous input gate, cell state, input and gradients\n        i_next = torch.mm(torch.cat((lstm1_hidden_output, c_prev, i_prev), 1), self.WI) + self.bI.expand_as(i_prev)\n        sig_i_next = torch.sigmoid(i_next)\n\n        # Update the cell state using the forget gate and input gate\n        c_next = sig_f_next * c_prev - sig_i_next * grad\n\n        # Pack the outputs into a list and return\n        outputs = [f_next, i_next, c_next]\n        return c_next, outputs\n\n\nclass MetaLearner(nn.Module):\n    \"\"\"\n    MetaLearner Module is a 2-layer LSTM, where the first layer is\n    a normal LSTM and the second layer is the MetaLSTMCell. The gradients and losses\n    are preprocessed and fed into the first layer LSTM, and the regular gradient coordinates are\n    used by the second layer LSTM to implement the state update rule. At each time step,\n    the learner’s loss and gradient is computed on a batch consisting of the entire training set Dtrain.\n    \"\"\"\n    def __init__(self, input_size, hidden_size, n_learner_params):\n        super(MetaLearner, self).__init__()\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.n_learner_params = n_learner_params\n        \n        # First Layer LSTM\n        self.lstm1 = nn.LSTMCell(input_size, hidden_size) \n        \n        # Second Layer MetaLSTMCell\n        self.lstm2 = MetaLSTMCell(hidden_size, 1, n_learner_params) \n        # input_size of MetaLSTMCell should be the hidden_size of self.lstm1\n        # hidden_size of MetaLSTMCell should be 1\n        # because cI is [n_params_len, 1] output is updated cI should also be [n_params_len, 1] \n    \n    # Forward pass\n    def forward(self, inputs, hs=None):\n        \n        # Unpack preprocessed gradients and losses\n        losses_prep, grads_prep, grads = inputs\n        \n        if hs is None:\n            hs = [None, None]\n        \n        # Concatenate and resize\n        loss = losses_prep.expand_as(grads_prep)\n        inputs = torch.cat((loss, grads_prep), 1)   # [n_learner_params, 4]\n#         print(f' meta learner inputs shape {inputs.shape}')\n\n        # Feed inputs to first layer LSTM\n        lstmhx, lstmcx = self.lstm1(inputs, hs[0]) # input_size = 4, hidden_size = 20\n#         print(f' meta learner lstm1 ht shape: {lstmhx.shape} ct shape :{lstmcx.shape}')\n        \n        # Feed output of first layer LSTM and regular gradient coordinates to second layer LSTM\n        flat_learner_unsqzd, lstm2_outputs = self.lstm2([lstmhx, grads], hs[1]) \n        \n        c_next = flat_learner_unsqzd.squeeze()\n        f_next, i_next, c_next = lstm2_outputs\n\n        return c_next, [(lstmhx, lstmcx), lstm2_outputs] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 3: Function definitions**\n\nAdditional functions used in the train/validate/test routines are defined below:\n\n* reshape_input_target: Structures the train and test input into specified array sizes\n\n* get_flat_grads: Extracts flattened gradient information from a model, normalized by batch size\n\n* scale_sign: Normalizes values of losses and gradients so that the meta-learner is able to use them properly during training. The preprocessing adjusts the scaling of gradients and losses, and separates magnitude and sign information (hence a pair of variables). The equation is as follows:\n\n$$x \\rightarrow \\begin{cases}\n    [\\frac{ln|x|}{p}, sgn(x)], &\\text{if } x \\geq e^{-p}\\\\\n    [-1, e^p \\,x], &\\text{otherwise}\n    \\end{cases}$$\n\n* epoch_loop: Trains the epoch_learner with $D_{train}$ datasets during meta-training","metadata":{}},{"cell_type":"code","source":"def reshape_input_target(episode, num_shot=5, num_eval=15, num_class=5):\n    \"\"\"\n    Structures the train and test input into specified array sizes\n    \"\"\"\n    train_input = episode[:, :num_shot].reshape(-1, *episode.shape[-3:]).to(device)   # [num_class * num_shot, 3x32x32]\n    train_target = torch.LongTensor(np.repeat(range(num_class), num_shot)).to(device) # [num_class * num_shot]\n    test_input = episode[:, num_shot:].reshape(-1, *episode.shape[-3:]).to(device)    # [num_class * num_eval, 3x32x32]\n    test_target = torch.LongTensor(np.repeat(range(num_class), num_eval)).to(device)  # [num_class * num_eval]\n    \n    return train_input, train_target, test_input, test_target\n\ndef get_flat_grads(model, batch_size):\n    grad_list = []\n    \n    for param in model.parameters():\n        grad_list.append(param.grad.data.view(-1) / batch_size)\n    \n    return torch.cat(grad_list, 0)\n\ndef scale_sign(x):\n    p = 10 # Paper: suggested value of p = 10 worked well\n    \n    # Check case and convert bool variable to float\n    indicator = (x.abs() >= np.exp(-p)).to(torch.float32)\n\n    # Preprocess x\n    x1 = indicator * torch.log(x.abs() + 1e-8) / p + (1 - indicator) * -1\n    x2 = indicator * torch.sign(x) + (1 - indicator) * np.exp(p) * x\n\n    return torch.stack((x1, x2), 1)\n\ndef epoch_loop(epoch_learner, metalearner, train_input, train_target, num_epoch=NUM_EPOCH, batch_size=BATCH_SIZE):\n    \n    # Extract epoch_learner parameters and hidden state information from metalearner\n    cI = metalearner.lstm2.cI.data\n    hs = [None]\n    \n    # Epoch loop\n    for _ in range(num_epoch):\n\n        # Batch size loop\n        for i in range(0, len(train_input), batch_size):\n\n            # Extract training data (x) and labels (y) for each batch\n            x = train_input[i:i+batch_size]\n            y = train_target[i:i+batch_size]\n\n            # Copy parameters of epoch_learner model from metalearner output cI\n            epoch_learner.copy_flat_params(cI)\n\n            # Compute predictions\n            output = epoch_learner(x) # [batch_size , n_class]\n\n            # Compute loss\n            loss = epoch_learner.criterion(output, y) \n#                 print('Epoch: {} \\tLearnerLoss: {:.4f}'.format(_ + 1, loss.item()))\n\n            # Update gradients\n            epoch_learner.zero_grad()\n            loss.backward()\n\n            # Extract gradient information as a flattened vector, normalized by batch size\n            grads = get_flat_grads(epoch_learner, batch_size)\n\n            # Preprocess gradients and loss information before feeding to metalearner\n            grads_prep = scale_sign(grads)                   # [n_learner_params, 2] \n            losses_prep = scale_sign(loss.data.unsqueeze(0)) # [1, 2]\n\n            metalearner_input = [losses_prep, grads_prep, grads.unsqueeze(1)]\n\n            # Compute updated metalearner predictions on epoch_learner parameters cI\n            cI, h = metalearner(metalearner_input, hs[-1])\n#             hs.append(h)\n    \n    return cI","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 4: Data preparation**\n\nThis section preprocesses and loads the image data as follows:\n\n* Resize to $64 \\times 64$ or $96 \\times 96$ pixels\n\n* Random horizontal flip (train only)\n\n* Normalization\n\n* Meta-train/test/validation split of 964/347/312 classes\n\nOriginal implementation also includes color jitter, which is excluded from this implementation for now due to the image size. Color will likely be a distinguishing feature for certain classes (e.g., apple).","metadata":{}},{"cell_type":"code","source":"# DATA PREPROCESSING\n# Omniglot download and folder reshuffling\nroot = BG_IMG_DIR\ntrain_root = TRAIN_IMG_DIR\n\nif not os.path.isdir(train_root): \n    os.mkdir(train_root)\n    \nfor language_folder in os.listdir(root):\n    language_folder_path = os.path.join(root,language_folder)\n    for character_folder in os.listdir(language_folder_path):\n        current_folder = os.path.join(language_folder_path,character_folder)\n        dst = os.path.join(train_root,language_folder+'_'+character_folder)\n#         print(current_folder,dst)\n        shutil.copytree(current_folder,dst)\n\nroot = EV_IMG_DIR\nval_root = VAL_IMG_DIR\ntest_root = TEST_IMG_DIR\n\nif not os.path.isdir(val_root): \n    os.mkdir(val_root)\nif not os.path.isdir(test_root): \n    os.mkdir(test_root)\n    \nfor i,language_folder in enumerate(os.listdir(root)):\n    language_folder_path = os.path.join(root,language_folder)\n    for character_folder in os.listdir(language_folder_path):\n        current_folder = os.path.join(language_folder_path,character_folder)\n        \n        if i < 10: # put to val\n            dst = os.path.join(val_root,language_folder+'_'+character_folder)\n        else:\n            dst = os.path.join(test_root,language_folder+'_'+character_folder)\n            \n#         print(current_folder,dst)\n        shutil.copytree(current_folder,dst)\n\n# Compute no. of classes\nnum_folders_train = len([f for f in os.listdir(TRAIN_IMG_DIR) if os.path.isdir(os.path.join(TRAIN_IMG_DIR, f))])\nnum_folders_val = len([f for f in os.listdir(VAL_IMG_DIR) if os.path.isdir(os.path.join(VAL_IMG_DIR, f))])\nnum_folders_test = len([f for f in os.listdir(TEST_IMG_DIR) if os.path.isdir(os.path.join(TEST_IMG_DIR, f))])\n# print(f'The directory {TRAIN_IMG_DIR} contains {TRAIN_IMG_DIR} folders')\n\n# Transformation for training data\ntransform_train = transforms.Compose([\n#     transforms.RandomHorizontalFlip(),  # Remove for omniglot\n    transforms.Resize((IMAGE_DIM,IMAGE_DIM)),\n#     transforms.ColorJitter(\n#         brightness=0.4,\n#         contrast=0.4,\n#         saturation=0.4,\n#         hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Transformation for testing and validation data\ntransform_test_val = transforms.Compose([\n    transforms.Resize((IMAGE_DIM,IMAGE_DIM)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load train data\ntrain_set = EpisodeDataset(root=TRAIN_IMG_DIR, num_shot=NUM_SHOT, num_eval=NUM_EVAL, transform=transform_train)\ntrain_loader = DataLoader(train_set, num_workers=2, pin_memory=True,\n        batch_sampler=EpisodeSampler(len(train_set), num_class=NUM_CLASS, num_episode=NUM_EPI_TRAIN))\nprint(f'Meta train sets created and loaded ({num_folders_train} classes)')\n\n# Load validation data\nval_set = EpisodeDataset(root=VAL_IMG_DIR, num_shot=NUM_SHOT, num_eval=NUM_EVAL, transform=transform_test_val)\nval_loader = DataLoader(val_set, num_workers=2, pin_memory=False,\n        batch_sampler=EpisodeSampler(len(val_set), num_class=NUM_CLASS, num_episode=NUM_EPI_EVAL))\nprint(f'Meta val sets created and loaded ({num_folders_val} classes)')\n\n# Load test data\ntest_set = EpisodeDataset(root=TEST_IMG_DIR, num_shot=NUM_SHOT, num_eval=NUM_EVAL, transform=transform_test_val)\ntest_loader = DataLoader(test_set, num_workers=2, pin_memory=False,\n        batch_sampler=EpisodeSampler(len(test_set), num_class=NUM_CLASS, num_episode=NUM_EPI_TEST))\nprint(f'Meta test sets created and loaded ({num_folders_test} classes)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 5: Initialize models and optimizer**\n\nPrepare models and optimizer for training.","metadata":{}},{"cell_type":"code","source":"# MODEL INITIALIZATION\nepoch_learner = Learner(num_class=NUM_CLASS, image_size=IMAGE_DIM, momentum=MOMENTUM, eps=EPS).to(device)   # Loops over epochs\nepisode_learner = Learner(num_class=NUM_CLASS, image_size=IMAGE_DIM, momentum=MOMENTUM, eps=EPS).to(device) # Loops over episodes\n# baseline_learner = Learner(num_class=NUM_CLASS, image_size=IMAGE_DIM, momentum=MOMENTUM, eps=EPS).to(device) # For baseline implementation\nprint('LEARNER models created')\nsummary(epoch_learner, (3, IMAGE_DIM, IMAGE_DIM), BATCH_SIZE)\n# summary(episode_learner, (3, IMAGE_DIM, IMAGE_DIM), BATCH_SIZE)\n\nmetalearner = MetaLearner(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, n_learner_params=epoch_learner.get_flat_params().size(0)).to(device)\nmetalearner.lstm2.init_cI(epoch_learner.get_flat_params())\nprint('META-LEARNER model created')\n# print(metalearner)\n\n# OPTIMIZER\noptimizer = torch.optim.Adam(metalearner.parameters(), LR_INIT)\n# baseline_optimizer = torch.optim.Adam(baseline_learner.parameters(), LR_INIT)\nprint('Optimizers created')\n# print(optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 6: Meta-Training**\n\nA total of 12000 episodes was used for meta-training, 100 episodes for meta-validation (every 100 meta-training episodes), and 1000 episodes for meta-testing. Each episode comprised n_shot + n_eval images for each of n_way classes. The batch size was set to 25, so each episode contained 25 training images and 75 testing images.","metadata":{}},{"cell_type":"code","source":"# MODEL TRAINING\n# Set TRAIN_FLAG to 0 to skip training and go straight to meta-testing (next section)\nTRAIN_FLAG = 1\nseed = np.random.randint(1, 10000)\ntorch.manual_seed(seed)\nprint('Used seed : {}'.format(seed))\n\ntbwriter = SummaryWriter(log_dir=LOG_DIR)\nprint('TensorboardX summary writer created')\n\ntotal_steps = 1\n   \nif TRAIN_FLAG: \n    \n    print('Start training')\n    train_acc_100 = []# Training accuracy per episodes\n    train_acc_all = [] # Training accuracy per 100 episodes\n    best_train_acc = 0\n    best_train_ep = 0\n    val_acc_all = [] # Average validation accuracy per episode at each set of Val\n    best_val_acc = 0\n    best_val_ep = 0\n    \n    # Episode loop (meta-train)\n    for ep, (episode, _) in enumerate(train_loader): \n        \n        # Reshape meta-train episode data\n        train_input, train_target, test_input, test_target = reshape_input_target(\n            episode,\n            num_shot=NUM_SHOT,\n            num_eval=NUM_EVAL,\n            num_class=NUM_CLASS\n        )\n\n        # Erase batch stats for each episode\n        epoch_learner.erase_batch_stats()\n        episode_learner.erase_batch_stats()     \n        # this is the reason in the original repo, author create a learner_wo_grad\n        # by right retain_graph=True should solve \n        # https://stackoverflow.com/questions/46774641/what-does-the-parameter-retain-graph-mean-in-the-variables-backward-method\n        # not working\n        \n        # Set to train mode\n        epoch_learner.train()\n        episode_learner.train()\n        \n        # Epoch loop\n        cI = epoch_loop(\n            epoch_learner, \n            metalearner, \n            train_input, \n            train_target, \n            num_epoch=NUM_EPOCH, \n            batch_size=BATCH_SIZE\n        )       \n\n        # Copy parameters of learner model from metalearner output cI after the last epoch of the episode\n        episode_learner.transfer_params(epoch_learner, cI)\n\n        # Compute predictions on test data\n        output = episode_learner(test_input)\n        \n        # Update loss\n        loss = episode_learner.criterion(output, test_target)\n        \n        # Update gradients\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # Apply gradient clipping (to manage exploding gradients issue with LSTM)\n        nn.utils.clip_grad_norm_(metalearner.parameters(), GRAD_CLIP)\n        \n        optimizer.step()\n        \n        # Compute accuracy\n        with torch.no_grad():\n            _, preds = torch.max(output, 1)\n            episode_acc = torch.sum(preds == test_target).item()/len(test_target)\n        train_acc_100.append(episode_acc)\n        \n        # Log the information and add to tensorboard\n        if (ep+1) % 50 == 0:\n            print('Episode: {}/{} \\tTrainingLoss: {:.4f} \\tEpisodeAcc: {:.2f}%'\n                .format(ep + 1, NUM_EPI_TRAIN, loss.item(), episode_acc * 100))\n            tbwriter.add_scalar('train_loss', loss.item())\n            tbwriter.add_scalar('train_accuracy', episode_acc)\n        \n        # Show best accuracy\n        if episode_acc > best_train_acc:\n            best_train_acc = episode_acc\n            best_train_ep = ep+1\n            print('Best training accuracy is from training episode {}: {:.2f}%'\n                  .format(best_train_ep, best_train_acc * 100))\n                \n        # Episode loop (meta-val)\n        if (ep+1) % VAL_FREQ == 0:\n            \n            # Compute average training loss\n            train_acc_all.append(np.mean(train_acc_100))\n            train_acc_100 = []\n            \n            # Reset mean val accuracy and loss\n            val_acc_total = 0\n            val_loss_total = 0\n            \n            # Episode loop (meta-val)\n            for val_ep, (val_episode, _) in enumerate(val_loader):\n                \n                # Reshape meta-val episode data\n                train_input, train_target, test_input, test_target = reshape_input_target(\n                    val_episode,\n                    num_shot=NUM_SHOT,\n                    num_eval=NUM_EVAL,\n                    num_class=NUM_CLASS\n                )\n        \n                # Erase batch stats for each episode\n                epoch_learner.erase_batch_stats()\n                episode_learner.erase_batch_stats()     \n\n                # Set to train/eval mode\n                epoch_learner.train()\n                episode_learner.eval()  # No training for episode_learner - why?\n\n                # Epoch loop\n                cI = epoch_loop(\n                    epoch_learner, \n                    metalearner, \n                    train_input, \n                    train_target, \n                    num_epoch=NUM_EPOCH, \n                    batch_size=BATCH_SIZE\n                )       \n\n                # Copy parameters of learner model from metalearner output cI after the last epoch of the episode\n                episode_learner.transfer_params(epoch_learner, cI)\n\n                # Compute predictions on test data\n                output = episode_learner(test_input)\n\n                # Update validation loss\n                loss = episode_learner.criterion(output, test_target)\n\n                # Compute validation episode accuracy\n                with torch.no_grad():\n                    _, preds = torch.max(output, 1)\n                    val_episode_acc = torch.sum(preds == test_target).item()/len(test_target)\n#                     val_episode_acc = val_episode_acc.item()/test_target.size()\n                \n                # Compute total validation loss and accuracy\n                val_loss_total = val_loss_total + loss.item()\n                val_acc_total = val_acc_total + val_episode_acc\n            \n            # Compute validation episode mean accuracy and loss and add to tensorboard\n            val_episode_loss_mean = val_loss_total/(val_ep+1)\n            val_episode_acc_mean = val_acc_total/(val_ep+1)\n            val_acc_all.append(val_episode_acc_mean)\n            tbwriter.add_scalar('val_loss', val_episode_loss_mean)\n            tbwriter.add_scalar('val_accuracy', val_episode_acc_mean)\n\n            # Show best accuracy and save best models\n            if val_episode_acc_mean > best_val_acc:\n                best_val_acc = val_episode_acc_mean\n                best_val_ep = ep+1\n                print('Best validation accuracy is from training episode {}: {:.2f}%'\n                      .format(best_val_ep, best_val_acc * 100))\n\n                # Save checkpoints - metalearner\n                meta_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'metalearner_best.pth')\n                torch.save(metalearner.state_dict(), meta_checkpoint_path)\n#                 print(f'Saved metalearner model weights to {meta_checkpoint_path}')\n\n                # Save checkpoints - learner\n                learner_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'learner_best.pth')\n                torch.save(episode_learner.state_dict(), learner_checkpoint_path)\n#                 print(f'Saved learner model weights to {learner_checkpoint_path}')\n\n                # Save checkpoints - optimizer\n                optimizer_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'optimizer_best.pth')\n                torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n#                 print(f'Saved optimizer weights to {optimizer_checkpoint_path}')\n                    \n                print(f'Saved model and optimizer weights to {CHECKPOINT_DIR}')\n        \nprint('Best training accuracy is from training episode {}: {:.2f}%'\n      .format(best_train_ep, best_train_acc * 100))\nprint('Best validation accuracy is from training episode {}: {:.2f}%'\n      .format(best_val_ep, best_val_acc * 100))\n\nplt.figure(1)\nplt.plot(train_acc_all, label='Training')\nplt.plot(val_acc_all, label='Validation')\nplt.xlabel('Episodes (x100)')\nplt.ylabel('Average accuracy per 100 episodes')\nplt.title('Training and validation accuracy (0-1)')\nplt.legend()\n\nplt.figure(2)\nplt.plot(train_acc_all, label='Training')\nplt.xlabel('Episodes (x100)')\nplt.ylabel('Average training accuracy per 100 episodes)')\nplt.title('Training accuracy (0-1)')\n\nplt.figure(3)\nplt.plot(val_acc_all, label='Validation')\nplt.xlabel('Episodes (x100)')\nplt.ylabel('Average validation accuracy per 100 episodes)')\nplt.title('Validation accuracy (0-1)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 7: Meta-Testing**\n\n1000 episodes were used for meta-testing. The mean, max, min, and standard deviation of test accuracy were computed to assess the meta-learner's performance.","metadata":{}},{"cell_type":"code","source":"# MODEL TEST\n\n# Load best validation round parameters\nmetalearner_state = torch.load(meta_checkpoint_path, map_location=device)\nmetalearner.load_state_dict(metalearner_state)\nlearner_state = torch.load(learner_checkpoint_path, map_location=device)\nepoch_learner.load_state_dict(learner_state)\nepisode_learner.load_state_dict(learner_state)\n\n# Initialize accuracy and loss\ntest_acc_total = 0\ntest_acc_all = np.zeros([NUM_EPI_TEST,1])\ntest_loss_total = 0\n\n# Episode loop (meta-test)\nfor test_ep, (test_episode, _) in enumerate(test_loader):\n\n    # Reshape meta-val episode data\n    train_input, train_target, test_input, test_target = reshape_input_target(test_episode,num_shot=NUM_SHOT,num_eval=NUM_EVAL,num_class=NUM_CLASS)\n\n    # Erase batch stats for each episode\n    epoch_learner.erase_batch_stats()\n    episode_learner.erase_batch_stats()     \n\n    # Set to train/eval mode\n    epoch_learner.train()\n    episode_learner.eval()  # No training for episode_learner - why?\n\n    # Epoch loop\n    cI = epoch_loop(epoch_learner, metalearner, train_input, train_target, num_epoch=NUM_EPOCH, batch_size=BATCH_SIZE)       \n\n    # Copy parameters of learner model from metalearner output cI after the last epoch of the episode\n    episode_learner.transfer_params(epoch_learner, cI)\n\n    # Compute predictions on test data\n    output = episode_learner(test_input)\n\n    # Update test loss\n    loss = episode_learner.criterion(output, test_target)\n\n    # Compute test episode accuracy\n    with torch.no_grad():\n        _, preds = torch.max(output, 1)\n        test_episode_acc = torch.sum(preds == test_target).item()/len(test_target)\n#         print(test_episode_acc)\n    test_acc_all[test_ep] = test_episode_acc\n\n    # Compute total test loss and accuracy\n    test_loss_total = test_loss_total + loss.item()\n    test_acc_total = test_acc_total + test_episode_acc\n\n# Compute test episode accuracies and loss\ntest_loss_mean = test_loss_total/NUM_EPI_TEST\ntest_acc_mean = np.mean(test_acc_all)\ntest_acc_max = np.max(test_acc_all)\ntest_acc_min = np.min(test_acc_all)\ntest_acc_std = np.std(test_acc_all)\n\nprint('Mean meta-test loss: {:.4f}'.format(test_loss_mean))\nprint('Mean meta-test accuracy: {:.2f}%'.format(test_acc_mean*100))\nprint('Max accuracy: {:.2f}% \\tMin accuracy: {:.2f}% \\tStd deviation: {:.2f}%'.format(test_acc_max*100, test_acc_min*100, test_acc_std*100))\n\nplt.figure(4)\nplt.hist(test_acc_all)\nplt.xlabel('Test accuracy')\nplt.ylabel('No. of episodes')\nplt.title('Test accuracy - histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 8: Baseline setting**\n\nBaseline accuracy was found using KNN (n_shot-neighbors) for 1000 episodes.","metadata":{}},{"cell_type":"code","source":"def compute_mean_features(support_set):\n    \"\"\"\n    Computes flattened 2-channel mean vector [NUM_IMAGES, IMAGE_DIM*IMAGE_DIM]\n    \"\"\"\n    image_means = []\n    \n    for image in support_set:\n        image_mean = np.mean(image, axis=0)\n        image_means.append(image_mean)\n    \n    return np.stack(image_means).reshape([len(support_set),-1])\n\ndef classify_episode(knn, train_input, train_target, test_input, test_target):\n    \"\"\"\n    Uses KNN classifier to classify test query set using mean features from support set\n    \"\"\"\n    # Convert to mean features\n    train_input_mean_features = compute_mean_features(train_input)\n    test_input_mean_features = compute_mean_features(test_input)\n    # train_input_mean_features.shape\n\n    # Fit KNN classifier\n    knn.fit(train_input_mean_features, train_target)\n\n    # Predict classes for the query set\n    predicted_classes = knn.predict(test_input_mean_features)\n\n    # Compute the accuracy\n    accuracy = (predicted_classes == test_target).mean()\n\n    return accuracy\n\n# Classification runs\nbaseline_test_acc_all = []\nknn = KNeighborsClassifier(n_neighbors=NUM_SHOT)\n# knn = KNeighborsClassifier(n_neighbors=1)\n\nfor test_ep, (test_episode, _) in enumerate(test_loader):\n\n    # Reshape episode data and convery to numpy arrays\n    train_input, train_target, test_input, test_target = reshape_input_target(\n        test_episode,\n        num_shot=NUM_SHOT,\n        num_eval=NUM_EVAL,\n        num_class=NUM_CLASS\n    )\n    train_input = train_input.cpu().numpy()\n    train_target = train_target.cpu().numpy()\n    test_input = test_input.cpu().numpy()\n    test_target = test_target.cpu().numpy()\n    \n    # Classify with KNN\n    baseline_test_acc = classify_episode(knn, train_input, train_target, test_input, test_target)\n    baseline_test_acc_all.append(baseline_test_acc)\n\nbaseline_test_acc_mean = np.mean(baseline_test_acc_all)\nbaseline_test_acc_max = np.max(baseline_test_acc_all)\nbaseline_test_acc_min = np.min(baseline_test_acc_all)\nbaseline_test_acc_std = np.std(baseline_test_acc_all)\n\nprint('Mean baseline test accuracy: {:.2f}%'.format(baseline_test_acc_mean*100))\nprint('Max accuracy: {:.2f}% \\tMin accuracy: {:.2f}% \\tStd deviation: {:.2f}%'\n      .format(baseline_test_acc_max*100, baseline_test_acc_min*100, baseline_test_acc_std*100))\n\nplt.figure(5)\nplt.hist(baseline_test_acc_all)\nplt.xlabel('Baseline test accuracy')\nplt.ylabel('No. of episodes')\nplt.title('Baseline test accuracy - histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Appendix: debug codes**","metadata":{}},{"cell_type":"code","source":"# Visualization checks\n\n# # train_set - print first 5 episodes\n# print(f\"Total no. of classes: {len(train_set)}\")\n\n# counter = 1\n\n# for data, label in test_set:\n#     print(f\"Data shape: {data.shape}\")\n#     print(f\"Label shape: {label.shape}\")\n#     print(label)\n    \n#     for i in range(data.size()[0]):\n#         disp_image = data[i]\n\n#         # Convert the tensor to a numpy array\n#         disp_image = disp_image.numpy()\n\n#         # Transpose the dimensions of the image to match the expected format\n#         disp_image = disp_image.transpose(1, 2, 0)\n\n#         # Display the image using matplotlib\n#         plt.imshow(disp_image)\n#         plt.show()\n    \n#     counter = counter + 1\n    \n#     if counter > 5:\n#         break\n\n# # train_loader\n# print(len(train_loader))\n\n# for batch in train_loader:\n#     data, labels = batch\n#     print(f\"Data shape: {data.shape}\")\n#     print(f\"Labels shape: {labels.shape}\")\n#     print(labels)\n\n# # Reshape function\n# for eps, (episode, _) in enumerate(train_loader): \n#     train_input, train_target, test_input, test_target = reshape_input_target(episode, num_shot=1, num_eval=15, num_class=5)\n#     print(train_target)\n#     print(test_target)\n#     break\n\n# Print model parameters\n# for name, param in learner.named_parameters():\n#     if name == 'model.linear.weight':\n#         print('Learner linear weights', param)\n        \n# for name, param in new_learner.named_parameters():\n#     if name == 'model.linear.weight':\n#         print('New learner linear weights', param)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.autograd.set_detect_anomaly(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.listdir('/kaggle/working/models')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}